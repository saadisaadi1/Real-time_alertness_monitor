{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    " #imports\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "import requests\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time\n",
    "import datetime"
   ],
   "id": "3d36f49787fe9c44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#loading datasets\n",
    "download_path = kagglehub.dataset_download(\"olgaparfenova/daisee\")\n",
    "\n",
    "print(\"Dataset downloaded to:\", download_path)\n",
    "print(\"Files:\", os.listdir(download_path))"
   ],
   "id": "3f8f32fc92d7c8e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SAMPLE_EVERY_SECONDS = 10\n",
    "CAMERA_INDEX = 0  # try 1 if 0 doesn't work"
   ],
   "id": "c7de5511f09ae20c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "MODEL_URL = (\n",
    "    \"https://storage.googleapis.com/mediapipe-models/face_detector/\"\n",
    "    \"blaze_face_short_range/float16/latest/blaze_face_short_range.tflite\"\n",
    ")\n",
    "MODEL_PATH = \"blaze_face_short_range.tflite\"\n",
    "\n",
    "def ensure_model(path=MODEL_PATH, url=MODEL_URL):\n",
    "    if os.path.exists(path):\n",
    "        return path\n",
    "    print(\"Downloading MediaPipe face model...\")\n",
    "    r = requests.get(url, stream=True, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    with open(path, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1 << 20):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    print(\"Saved model to:\", path)\n",
    "    return path\n",
    "\n",
    "def create_face_detector():\n",
    "    model_path = ensure_model()\n",
    "    base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "    options = vision.FaceDetectorOptions(base_options=base_options)\n",
    "    return vision.FaceDetector.create_from_options(options)\n",
    "\n",
    "def detect_and_draw_box_tasks(detector, frame_bgr):\n",
    "    # MediaPipe Tasks expects RGB\n",
    "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "\n",
    "    result = detector.detect(mp_image)\n",
    "    if not result.detections:\n",
    "        return frame_bgr, False\n",
    "\n",
    "    # take best detection by confidence\n",
    "    best = max(result.detections, key=lambda d: d.categories[0].score)\n",
    "    bbox = best.bounding_box  # pixel coords\n",
    "    x1, y1 = int(bbox.origin_x), int(bbox.origin_y)\n",
    "    x2, y2 = x1 + int(bbox.width), y1 + int(bbox.height)\n",
    "\n",
    "    h, w = frame_bgr.shape[:2]\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    x2, y2 = min(w - 1, x2), min(h - 1, y2)\n",
    "\n",
    "    out = frame_bgr.copy()\n",
    "    cv2.rectangle(out, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    score = best.categories[0].score\n",
    "    cv2.putText(out, f\"Face {score:.2f}\", (x1, max(0, y1 - 10)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    return out, True\n"
   ],
   "id": "45384a1b86530a9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SAMPLE_EVERY_SECONDS = 10\n",
    "CAMERA_INDEX = 0\n",
    "\n",
    "my_detector = create_face_detector()\n",
    "\n",
    "cap = cv2.VideoCapture(CAMERA_INDEX)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Could not open webcam\")\n",
    "\n",
    "next_sample_time = time.time() + SAMPLE_EVERY_SECONDS\n",
    "print(\"Live webcam started. Press 'q' in the video window to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read frame\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Live Webcam\", frame)\n",
    "\n",
    "    now = time.time()\n",
    "    if now >= next_sample_time:\n",
    "        boxed, found = detect_and_draw_box_tasks(my_detector, frame)\n",
    "\n",
    "        if found:\n",
    "            print(f\"[{now:.2f}] Face detected ✅\")\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.imshow(cv2.cvtColor(boxed, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Sampled frame (MediaPipe Tasks face box)\")\n",
    "            plt.show()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"[{now:.2f}] No face detected ❌\")\n",
    "\n",
    "        next_sample_time = now + SAMPLE_EVERY_SECONDS\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "my_detector.close()"
   ],
   "id": "b1e00e9993a07815"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
